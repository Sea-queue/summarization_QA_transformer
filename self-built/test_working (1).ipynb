{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c48af91d",
      "metadata": {
        "id": "c48af91d"
      },
      "outputs": [],
      "source": [
        "# importing necessary library\n",
        "import os\n",
        "# importing necessary library\n",
        "import kagglehub\n",
        "# importing necessary library\n",
        "import pandas as pd\n",
        "# importing necessary library\n",
        "import torch\n",
        "# importing necessary library\n",
        "import torch.nn as nn\n",
        "# importing necessary library\n",
        "import torch.nn.functional as F\n",
        "# importing necessary library\n",
        "import math\n",
        "# importing necessary library\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load a small portion (1%) of the scientific papers (arXiv) dataset\n",
        "dataset = load_dataset(\"scientific_papers\", \"arxiv\", split=\"train[:1%]\")\n"
      ],
      "metadata": {
        "id": "wDhSQb_dWxLJ"
      },
      "id": "wDhSQb_dWxLJ",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0].keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnFu70ECYyiC",
        "outputId": "f892ebad-8822-4e67-be71-1b78e6a08782"
      },
      "id": "pnFu70ECYyiC",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['article', 'abstract', 'section_names'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "# Training tokenizer from scratch using article → abstract\n",
        "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for sample in dataset:\n",
        "        f.write(sample['article'].replace(\"\\n\", \" \") + \"\\n\")   # input\n",
        "        f.write(sample['abstract'].replace(\"\\n\", \" \") + \"\\n\")  # target/summary\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train(\n",
        "    files=\"corpus.txt\",\n",
        "    vocab_size=30522,\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\"<s>\", \"</s>\", \"<pad>\", \"<unk>\"]\n",
        ")\n",
        "import os\n",
        "os.makedirs(\"custom_tokenizer\", exist_ok=True)\n",
        "tokenizer.save_model(\"custom_tokenizer\")\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"custom_tokenizer/vocab.json\",\n",
        "    \"custom_tokenizer/merges.txt\"\n",
        ")\n",
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\"))\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=128)\n"
      ],
      "metadata": {
        "id": "XLwPhn-LZG8Q"
      },
      "id": "XLwPhn-LZG8Q",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(example):\n",
        "    input_ids = tokenizer.encode(example[\"article\"]).ids[:128]\n",
        "    target_ids = tokenizer.encode(example[\"abstract\"]).ids[:32]\n",
        "\n",
        "    input_ids += [tokenizer.token_to_id(\"<pad>\")] * (128 - len(input_ids))\n",
        "    target_ids = [tokenizer.token_to_id(\"<s>\")] + target_ids + [tokenizer.token_to_id(\"</s>\")]\n",
        "    target_ids += [tokenizer.token_to_id(\"<pad>\")] * (34 - len(target_ids))\n",
        "\n",
        "    return {\"input_ids\": input_ids, \"labels\": target_ids}\n"
      ],
      "metadata": {
        "id": "Nb3VTvsgZfCr"
      },
      "id": "Nb3VTvsgZfCr",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(preprocess)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0fcca030740e4d20a7fb8dd3cb90b9b0",
            "270cb4f0bbe54989952294a2a824707d",
            "7ca0fe5a9a8449b98e95558f9e086410",
            "7cb3ccbce1b14333beabf2f43611cb54",
            "58273f0d39da461e84d85642c5273780",
            "b42cf480c3c2470cb8ead6cf0d4a455a",
            "0bec3c87a8b147a981379d78684b810d",
            "699c49ee669b4b1abbb2cd2d42e7e38d",
            "4dc3c53991bb456d89376b6d00049c30",
            "40783b79ba26403fa202e6b29e291ab3",
            "218a7ab62ace439db249419d13387e7b"
          ]
        },
        "id": "mkDKSnszbGIn",
        "outputId": "c03aa15a-eb46-43a2-df88-7c9214299184"
      },
      "id": "mkDKSnszbGIn",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2030 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fcca030740e4d20a7fb8dd3cb90b9b0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0].keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6ZQ2ISxcc8N",
        "outputId": "a513c6cc-583a-44db-a04c-8b149f9c0227"
      },
      "id": "a6ZQ2ISxcc8N",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['article', 'abstract', 'section_names', 'input_ids', 'labels'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b7b34f65",
      "metadata": {
        "id": "b7b34f65"
      },
      "outputs": [],
      "source": [
        "# Utility: Clone layers\n",
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "03d956e6",
      "metadata": {
        "id": "03d956e6"
      },
      "outputs": [],
      "source": [
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Creating constant 'pe' matrix\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Adding positional encoding\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "4cab4afa",
      "metadata": {
        "id": "4cab4afa"
      },
      "outputs": [],
      "source": [
        "# Layer Normalization\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "d022243c",
      "metadata": {
        "id": "d022243c"
      },
      "outputs": [],
      "source": [
        "# Sublayer Connection (Residual + Norm)\n",
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "25d793fb",
      "metadata": {
        "id": "25d793fb"
      },
      "outputs": [],
      "source": [
        "# Multi-Head Attention\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = torch.softmax(scores, dim=-1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ae402882",
      "metadata": {
        "id": "ae402882"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        query, key, value = [\n",
        "            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "            for l, x in zip(self.linears, (query, key, value))\n",
        "        ]\n",
        "\n",
        "        x, self.attn = attention(query, key, value, mask, self.dropout)\n",
        "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
        "        return self.linears[-1](x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "621976b1",
      "metadata": {
        "id": "621976b1"
      },
      "outputs": [],
      "source": [
        "# Position-wise Feed Forward\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "dac505dc",
      "metadata": {
        "id": "dac505dc"
      },
      "outputs": [],
      "source": [
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "18542cf1",
      "metadata": {
        "id": "18542cf1"
      },
      "outputs": [],
      "source": [
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "019dbf1a",
      "metadata": {
        "id": "019dbf1a"
      },
      "outputs": [],
      "source": [
        "# Encoder and Decoder Stacks\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3e828905",
      "metadata": {
        "id": "3e828905"
      },
      "outputs": [],
      "source": [
        "# Embeddings with Positional Encoding\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "e1f9794a",
      "metadata": {
        "id": "e1f9794a"
      },
      "outputs": [],
      "source": [
        "# Full model\n",
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "db870d99",
      "metadata": {
        "id": "db870d99"
      },
      "outputs": [],
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)\n",
        "\n",
        "# Mask to block future positions\n",
        "def subsequent_mask(size):\n",
        "    attn_shape = (1, size, size)\n",
        "    mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
        "    return mask == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "45ffd1f2",
      "metadata": {
        "id": "45ffd1f2"
      },
      "outputs": [],
      "source": [
        "# Build full model\n",
        "def make_model(vocab_size, N=6, d_model=768, d_ff=3072, h=8, dropout=0.2):\n",
        "    attn = MultiHeadedAttention(h, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, attn, ff, dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, attn, attn, ff, dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, vocab_size), position),\n",
        "        nn.Sequential(Embeddings(d_model, vocab_size), position),\n",
        "        Generator(d_model, vocab_size)\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions (for auto-regressive decoding)\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
        "    return subsequent_mask == 0\n"
      ],
      "metadata": {
        "id": "C8glCtJ9dD1H"
      },
      "id": "C8glCtJ9dD1H",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "b40c72da",
      "metadata": {
        "id": "b40c72da"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ArxivDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        src = torch.tensor(item[\"input_ids\"])\n",
        "        tgt = torch.tensor(item[\"labels\"])\n",
        "        return src, tgt\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = ArxivDataset(dataset)  # ← your preprocessed HuggingFace dataset\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "151a54c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "151a54c0",
        "outputId": "b9eb4604-1e13-4b39-ae9a-76f7b31845e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 6.9558\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 5.7299\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 5.3794\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 5.1046\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 4.8720\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 4.6610\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 4.4675\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 4.2920\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 4.1247\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.9667\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.8236\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.6873\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.5615\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.4354\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.3142\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.2044\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 3.0922\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.9892\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.8902\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.7890\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.6951\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.6025\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.5116\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.4167\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.3312\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.2414\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.1555\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 2.0715\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.9855\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.9006\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.8189\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.7381\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.6520\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.5734\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.4972\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.4237\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.3459\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.2804\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.2106\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.1476\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:33<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.0802\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:33<00:00,  7.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 1.0174\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.9569\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.9067\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.8559\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.8053\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.7576\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.7153\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.6735\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 254/254 [00:32<00:00,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 0.6408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Get vocab size and pad ID\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "pad_token_id = tokenizer.token_to_id(\"<pad>\")\n",
        "\n",
        "# Build model\n",
        "model = make_model(vocab_size).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_fn = nn.NLLLoss(ignore_index=pad_token_id)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in tqdm(train_loader):\n",
        "     src = src.to(device)\n",
        "     tgt = tgt.to(device)\n",
        "\n",
        "     tgt_input = tgt[:, :-1]\n",
        "     tgt_output = tgt[:, 1:]\n",
        "\n",
        "    # Create masks\n",
        "     src_mask = (src != pad_token_id).unsqueeze(-2)  # shape: [batch, 1, seq_len]\n",
        "     tgt_mask = (tgt_input != pad_token_id).unsqueeze(-2)  # shape: [batch, 1, tgt_len]\n",
        "     tgt_mask = tgt_mask & subsequent_mask(tgt_input.size(-1)).to(device)\n",
        "\n",
        "    # Forward pass with masks\n",
        "     out = model(src, tgt_input, src_mask, tgt_mask)\n",
        "     logits = model.generator(out)\n",
        "\n",
        "     logits = logits.view(-1, logits.size(-1))\n",
        "     tgt_output = tgt_output.contiguous().view(-1)\n",
        "\n",
        "     loss = loss_fn(logits, tgt_output)\n",
        "     optimizer.zero_grad()\n",
        "     loss.backward()\n",
        "     optimizer.step()\n",
        "\n",
        "     total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Average loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "3827f8cd",
      "metadata": {
        "id": "3827f8cd"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol, eos_symbol):\n",
        "    model.eval()\n",
        "    memory = model.encode(src, src_mask)\n",
        "\n",
        "    # Start with <s> token\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src).to(src.device)\n",
        "\n",
        "    for _ in range(max_len - 1):\n",
        "        tgt_mask = subsequent_mask(ys.size(1)).to(src.device).unsqueeze(1)\n",
        "        out = model.decode(memory, src_mask, ys, tgt_mask)\n",
        "\n",
        "        # Use sampling instead of argmax\n",
        "        probs = torch.softmax(model.generator(out[:, -1]), dim=-1)\n",
        "        next_word = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        ys = torch.cat([ys, next_word], dim=1)\n",
        "\n",
        "        # Stop decoding if </s> token is generated\n",
        "        if next_word.item() == eos_symbol:\n",
        "            break\n",
        "\n",
        "    return ys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "02011749",
      "metadata": {
        "id": "02011749"
      },
      "outputs": [],
      "source": [
        "def generate_summary(model, input_text, tokenizer, max_len=64):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input text (article)\n",
        "    input_ids = tokenizer.encode(input_text).ids[:128]\n",
        "    input_ids += [tokenizer.token_to_id(\"<pad>\")] * (128 - len(input_ids))\n",
        "    src = torch.tensor([input_ids]).to(next(model.parameters()).device)\n",
        "    src_mask = (src != tokenizer.token_to_id(\"<pad>\")).unsqueeze(-2)\n",
        "\n",
        "    # Special token IDs\n",
        "    start_symbol = tokenizer.token_to_id(\"<s>\")\n",
        "    eos_symbol = tokenizer.token_to_id(\"</s>\")\n",
        "\n",
        "    # Decode\n",
        "    decoded_ids = greedy_decode(model, src, src_mask, max_len, start_symbol, eos_symbol)\n",
        "\n",
        "    # Remove padding and decode to string\n",
        "    token_ids = [t for t in decoded_ids[0].tolist() if t not in [\n",
        "    tokenizer.token_to_id(\"<pad>\"),\n",
        "    tokenizer.token_to_id(\"<s>\"),\n",
        "    tokenizer.token_to_id(\"</s>\")]]\n",
        "\n",
        "    return tokenizer.decode(token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_dataset = load_dataset(\"scientific_papers\", \"arxiv\", split=\"train[:1%]\")\n"
      ],
      "metadata": {
        "id": "oCYGcYTVe9Cu"
      },
      "id": "oCYGcYTVe9Cu",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "4bd5ad26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bd5ad26",
        "outputId": "f4506257-ddd3-4daf-c244-69024cd123a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Title:  a model large class - electron systems with @xmath1 and in the _ \n",
            " the @xmath1\n"
          ]
        }
      ],
      "source": [
        "sample_abstract = raw_dataset[1][\"article\"]\n",
        "generated_title = generate_summary(model, sample_abstract, tokenizer)\n",
        "print(\"Generated Title:\", generated_title)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_dataset = load_dataset(\"scientific_papers\", \"arxiv\", split=\"train[:1%]\")\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"\\nSample {i+1}\")\n",
        "    article = raw_dataset[i][\"article\"]\n",
        "    target = raw_dataset[i][\"abstract\"]\n",
        "    predicted = generate_summary(model, article, tokenizer)\n",
        "\n",
        "    print(\" Reference:\", target[:200], \"...\")\n",
        "    print(\" Generated:\", predicted)\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "ZbAEGqpngf0j",
        "outputId": "ee3ed27c-2a09-44ff-d000-902ae39aa61d"
      },
      "id": "ZbAEGqpngf0j",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-18cece5f9fcf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scientific_papers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arxiv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train[:1%]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nSample {i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "def evaluate_model(model, tokenizer, dataset, n=5):\n",
        "    for i in range(n):\n",
        "        article = dataset[i][\"article\"]\n",
        "        reference = dataset[i][\"abstract\"]\n",
        "        generated = generate_summary(model, article, tokenizer)\n",
        "\n",
        "        scores = scorer.score(reference, generated)\n",
        "\n",
        "        print(f\"\\nSample {i+1}\")\n",
        "        print(f\" Reference: {reference[:150]}...\")\n",
        "        print(f\" Generated: {generated}\")\n",
        "        print(f\" ROUGE-1: {scores['rouge1'].fmeasure:.4f} | ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")\n",
        "        print(\"-\" * 80)\n"
      ],
      "metadata": {
        "id": "fAnm8-XFjnmu"
      },
      "id": "fAnm8-XFjnmu",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, tokenizer, raw_dataset, n=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNKryN9Bjt89",
        "outputId": "dbec8d5b-b069-47d9-9c3d-78bfdbcf5d5a"
      },
      "id": "aNKryN9Bjt89",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample 1\n",
            "🔹 Reference:  additive models play an important role in semiparametric statistics . \n",
            " this paper gives learning rates for regularized kernel based methods for addi...\n",
            "🔸 Generated:  because of major technology for regularized\n",
            "📈 ROUGE-1: 0.0444 | ROUGE-L: 0.0296\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sample 2\n",
            "🔹 Reference:  we have studied the leptonic decay @xmath0 , via the decay channel @xmath1 , using a sample of tagged @xmath2 decays collected near the @xmath3 peak ...\n",
            "🔸 Generated:  we like events which includes @xmath1 , where the @\n",
            "📈 ROUGE-1: 0.1270 | ROUGE-L: 0.1270\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sample 3\n",
            "🔹 Reference:  in 84 , 258 ( 2000 ) , mateos conjectured that current reversal in a classical deterministic ratchet is associated with bifurcations from chaotic to ...\n",
            "🔸 Generated:  at describing the signal comes from chaotic to moderate up to periodic regimes . \n",
            " this is . compactness\n",
            "📈 ROUGE-1: 0.0732 | ROUGE-L: 0.0569\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sample 4\n",
            "🔹 Reference:  the effect of a random phase diffuser on fluctuations of laser light ( scintillations ) is studied . \n",
            " not only spatial but also temporal phase varia...\n",
            "🔸 Generated:  at rhic ; time . \n",
            " not possible exoplanet the evolution of a random magnetic field is studied . \n",
            " not only dependent term plasticity changes in a quantum transport in a quantum wave only electric or a quantum fluctuations of a quantum is studied ; one layer security on fluctuations of a quantum interactions up to the effects . .\n",
            "📈 ROUGE-1: 0.3200 | ROUGE-L: 0.2400\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sample 5\n",
            "🔹 Reference:  with a special intention of clarifying the underlying spin contents of the nucleon , we investigate the generalized form factors of the nucleon , whi...\n",
            "🔸 Generated:  with a special intention of such that have zero eigenvalues of mean of physics of clarifying of the nucleon of the nucleon of and the nucleon of the degree of paper such as the exact but finite flexibility of data on measurements of understanding which are defined as the generalized of distances of core - point of the four core , which\n",
            "📈 ROUGE-1: 0.3251 | ROUGE-L: 0.2463\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fcca030740e4d20a7fb8dd3cb90b9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_270cb4f0bbe54989952294a2a824707d",
              "IPY_MODEL_7ca0fe5a9a8449b98e95558f9e086410",
              "IPY_MODEL_7cb3ccbce1b14333beabf2f43611cb54"
            ],
            "layout": "IPY_MODEL_58273f0d39da461e84d85642c5273780"
          }
        },
        "270cb4f0bbe54989952294a2a824707d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42cf480c3c2470cb8ead6cf0d4a455a",
            "placeholder": "​",
            "style": "IPY_MODEL_0bec3c87a8b147a981379d78684b810d",
            "value": "Map: 100%"
          }
        },
        "7ca0fe5a9a8449b98e95558f9e086410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699c49ee669b4b1abbb2cd2d42e7e38d",
            "max": 2030,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dc3c53991bb456d89376b6d00049c30",
            "value": 2030
          }
        },
        "7cb3ccbce1b14333beabf2f43611cb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40783b79ba26403fa202e6b29e291ab3",
            "placeholder": "​",
            "style": "IPY_MODEL_218a7ab62ace439db249419d13387e7b",
            "value": " 2030/2030 [00:59&lt;00:00, 35.02 examples/s]"
          }
        },
        "58273f0d39da461e84d85642c5273780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42cf480c3c2470cb8ead6cf0d4a455a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bec3c87a8b147a981379d78684b810d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "699c49ee669b4b1abbb2cd2d42e7e38d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc3c53991bb456d89376b6d00049c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40783b79ba26403fa202e6b29e291ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218a7ab62ace439db249419d13387e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}