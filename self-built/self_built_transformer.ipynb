{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization and Q&A Using Transformer\n",
    "\n",
    "- we need encoder-decoder architecture\n",
    "\n",
    "- Encoder is for\n",
    "\n",
    "- Decoder is for \n",
    "\n",
    "⸻\n",
    "\n",
    "1. Understand the Transformer Architecture\n",
    "\n",
    "At a high level, the original Transformer (from the 2017 paper) consists of:\n",
    "\t•\tInput Embedding (plus positional encoding)\n",
    "\t•\tEncoder Blocks (for encoding input)\n",
    "\t•\tDecoder Blocks (for generating output)\n",
    "\t•\tMulti-Head Self-Attention\n",
    "\t•\tFeedforward Neural Networks\n",
    "\t•\tLayer Normalization & Residual Connections\n",
    "\n",
    "⸻\n",
    "\n",
    "2. Minimal Setup (Start Here)\n",
    "\n",
    "Use PyTorch or TensorFlow — most people use PyTorch for scratch implementations.\n",
    "\n",
    "Basic Structure:\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(...)\n",
    "        self.decoder = Decoder(...)\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        encoder_output = self.encoder(src)\n",
    "        output = self.decoder(tgt, encoder_output)\n",
    "        return output\n",
    "\n",
    "⸻\n",
    "\n",
    "3. Core Components to Implement\n",
    "\t•\tPositional Encoding\n",
    "\t•\tMulti-Head Attention\n",
    "\t•\tLayer Normalization\n",
    "\t•\tFeed-Forward Layer\n",
    "\t•\tEncoder Layer (stacked N times)\n",
    "\t•\tDecoder Layer (stacked N times)\n",
    "\t•\tFinal Linear + Softmax for prediction\n",
    "\n",
    "⸻\n",
    "\n",
    "4. Helpful Resources\n",
    "\t•\tThe Annotated Transformer (PyTorch):\n",
    "\t•\thttps://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "\t•\tTransformer from scratch in PyTorch (YouTube):\n",
    "The AI Epiphany channel is gold for this.\n",
    "\n",
    "⸻\n",
    "\n",
    "5. Training Your Transformer\n",
    "\n",
    "Once you build the model:\n",
    "\t•\tChoose your dataset (e.g., for Q&A, use SQuAD; for summarization, try CNN/DailyMail).\n",
    "\t•\tTokenize your data.\n",
    "\t•\tDefine your loss (usually CrossEntropyLoss for text).\n",
    "\t•\tUse teacher forcing during training.\n",
    "\n",
    "⸻\n",
    "\n",
    "Optional: Start Small\n",
    "\n",
    "You can start by building:\n",
    "\t•\tJust the Encoder (like BERT)\n",
    "\t•\tOr a small Encoder-Decoder (like TinyT5)\n",
    "\n",
    "⸻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "- collect data:\n",
    "    - collect all the ids\n",
    "    - use https://arxiv.org/pdf/{id} to download pdf\n",
    "    - read and save all the pdf articles in to csv file.\n",
    "\n",
    "- which part of the transformer is controlling summarization vs translation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/Cornell-University/arxiv?dataset_version_number=225...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.42G/1.42G [00:39<00:00, 38.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/seaqueue/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/225\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"Cornell-University/arxiv\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arxiv-metadata-oai-snapshot.json']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:           id           submitter  \\\n",
      "0  0704.0001      Pavel Nadolsky   \n",
      "1  0704.0002        Louis Theran   \n",
      "2  0704.0003         Hongjun Pan   \n",
      "3  0704.0004        David Callan   \n",
      "4  0704.0005  Alberto Torchinsky   \n",
      "\n",
      "                                             authors  \\\n",
      "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
      "1                    Ileana Streinu and Louis Theran   \n",
      "2                                        Hongjun Pan   \n",
      "3                                       David Callan   \n",
      "4           Wael Abu-Shammala and Alberto Torchinsky   \n",
      "\n",
      "                                               title  \\\n",
      "0  Calculation of prompt diphoton production cros...   \n",
      "1           Sparsity-certifying Graph Decompositions   \n",
      "2  The evolution of the Earth-Moon system based o...   \n",
      "3  A determinant of Stirling cycle numbers counts...   \n",
      "4  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
      "\n",
      "                                  comments  \\\n",
      "0  37 pages, 15 figures; published version   \n",
      "1    To appear in Graphs and Combinatorics   \n",
      "2                      23 pages, 3 figures   \n",
      "3                                 11 pages   \n",
      "4                                     None   \n",
      "\n",
      "                                 journal-ref                         doi  \\\n",
      "0                   Phys.Rev.D76:013009,2007  10.1103/PhysRevD.76.013009   \n",
      "1                                       None                        None   \n",
      "2                                       None                        None   \n",
      "3                                       None                        None   \n",
      "4  Illinois J. Math. 52 (2008) no.2, 681-689                        None   \n",
      "\n",
      "          report-no       categories  \\\n",
      "0  ANL-HEP-PR-07-12           hep-ph   \n",
      "1              None    math.CO cs.CG   \n",
      "2              None   physics.gen-ph   \n",
      "3              None          math.CO   \n",
      "4              None  math.CA math.FA   \n",
      "\n",
      "                                             license  \\\n",
      "0                                               None   \n",
      "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                            abstract  \\\n",
      "0    A fully differential calculation in perturba...   \n",
      "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
      "2    The evolution of Earth-Moon system is descri...   \n",
      "3    We show that a determinant of Stirling cycle...   \n",
      "4    In this paper we show how to compute the $\\L...   \n",
      "\n",
      "                                            versions update_date  \\\n",
      "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
      "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
      "2  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2008-01-13   \n",
      "3  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2007-05-23   \n",
      "4  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2013-10-15   \n",
      "\n",
      "                                      authors_parsed  \n",
      "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
      "1           [[Streinu, Ileana, ], [Theran, Louis, ]]  \n",
      "2                                 [[Pan, Hongjun, ]]  \n",
      "3                                [[Callan, David, ]]  \n",
      "4  [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(path+'/arxiv-metadata-oai-snapshot.json', lines=True)\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    # TODO:\n",
    "    # what is generator?\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    \n",
    "    # what are these masks for why do we need two masks?\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        # take in and process maksed src and tgt sequences\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Standard linear + softmax generation step\n",
    "    '''\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: which activation function is the best for summarization?\n",
    "        return log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    # Produce N identical layers\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        'pass the input (and mask) through each layer in turn'\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    '''Construct a layernorm module (See citation for details).'''\n",
    "    # TODO: what is the purpose of eps?\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is this function trying to do? what is the input and output?\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Droputout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        # why add X to the tensor?\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(slef, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.subalyer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(tornch.uint8)\n",
    "\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = torch.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout = 0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        query, key, value = [\n",
    "            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for l, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        x = (x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k))\n",
    "\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "\n",
    "        return self.linears[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1);\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, d_model= 512, d_ff=2048, h=8, dropout=0.1):\n",
    "    c = copy.deeepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab)\n",
    "    )\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
